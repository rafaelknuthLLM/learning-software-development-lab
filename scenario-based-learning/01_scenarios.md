# SDLC Learning Through Real-World Discovery

**How This Works:** I (the learner) immerse myself as a newbie team member at Anthropic. I learn software development by discovering their actual codebase on GitHub, following SDLC and DevOps best practices.

**My Learning Journey:**
1. **First:** I completed Anthropic's 5-course curriculum (API, Prompting, Evaluations, Tools)
2. **Second:** Together with Claude Code, I created 6 practical scenarios based on those courses
3. **Third:** I apply course skills to systematically explore Anthropic's real codebase across GitHub

**Why This Approach:** Instead of artificial exercises, I learn each SDLC phase by discovering how Anthropic actually builds, tests, deploys, and maintains their systems.

## Course Foundation

**Anthropic's 5-Course Skills Foundation:**
- **API Fundamentals:** Technical foundation for connecting to Claude
- **Prompt Engineering:** Core communication skills with Claude  
- **Real World Prompting:** Professional application techniques
- **Prompt Evaluations:** Quality measurement and improvement
- **Tool Use:** Advanced system integration

**Setup Requirements:**
- Python 3.7.1+ with `anthropic`, `python-dotenv`, `jupyter`
- Anthropic API key (environment variables)
- Optional: `promptfoo` for evaluations

## Discovery Scenarios

**My Role-Play:** New team member discovering Anthropic's ecosystem across their entire GitHub presence.

**Discovery Scope:** Any Anthropic/community code that serves learning:
- Local cookbook/courses, Public repositories, Community contributions, Documentation sites, Third-party integrations

**Skills Integration:** At each SDLC phase, I practice all four competencies: API Integration, Prompt Engineering, Evaluation & Testing, Tool Integration.

**Quality Assurance Protocol:**
- **Validation:** Verify discoveries against official Anthropic documentation/team feedback
- **Documentation:** Follow standardized templates for knowledge capture and sharing
- **Community Review:** Share findings with Anthropic community for validation and contribution
- **Iteration:** Update scenarios based on learnings, feedback, and community input
- **Knowledge Sharing:** Learn in the open - document discoveries publicly for community benefit

### Scenario 1: Requirements Discovery through Ecosystem Analysis
**SDLC Phase:** Requirements Analysis  
**Discovery Focus:** What problems does Anthropic's ecosystem solve? What user needs drive the code?

**Skills Practice:**
- **API Integration:** Use Claude API to systematically catalog Anthropic's repositories and documentation
- **Prompt Engineering:** Write prompts that extract requirements insights from code comments, README files, and documentation
- **Evaluation:** Test prompt effectiveness at identifying true vs. assumed requirements
- **Tool Integration:** Build tools that automatically discover and categorize Anthropic ecosystem components

**Quality Gates:**
- Requirements analysis covers 80% of major Anthropic repositories
- Community validation confirms accuracy of discovered requirements
- Tools successfully categorize ecosystem components with 90% accuracy

**Deliverables:**
- Requirements analysis of Anthropic's educational and production code
- Discovery methodology documentation for future team members
- Automated tools for ecosystem exploration
- Public contribution to Anthropic community knowledge base

### Scenario 2: Architecture Discovery through Pattern Analysis
**SDLC Phase:** Design & Architecture  
**Discovery Focus:** How is Anthropic's ecosystem organized? What patterns repeat across implementations?

**Skills Practice:**
- **API Integration:** Use Claude to analyze code structure and identify architectural patterns
- **Prompt Engineering:** Create prompts that recognize design patterns, anti-patterns, and best practices
- **Evaluation:** Validate pattern recognition accuracy against known architectural principles
- **Tool Integration:** Build pattern analysis tools that work across multiple repositories

**Quality Gates:**
- Identify and document at least 10 recurring architectural patterns
- Pattern analysis tools validated by community feedback
- Best practices guide reviewed and approved by Anthropic community

**Deliverables:**
- Architecture documentation and pattern libraries
- Design pattern analysis tools for team knowledge sharing
- Best practices guide derived from real Anthropic implementations
- Community-validated architectural insights

### Scenario 3: Implementation Discovery through Code Analysis
**SDLC Phase:** Implementation  
**Discovery Focus:** How does Anthropic implement solutions? What coding practices do they follow?

**Skills Practice:**
- **API Integration:** Use Claude to understand implementation details and coding patterns
- **Prompt Engineering:** Write prompts that identify implementation best practices and code quality patterns
- **Evaluation:** Test understanding by comparing discovered practices with actual team standards
- **Tool Integration:** Create development tools that enforce discovered best practices

**Quality Gates:**
- Implementation guidelines cover key coding standards and practices
- Code analysis tools demonstrate measurable quality improvements
- Community validates discovered practices align with actual standards

**Deliverables:**
- Implementation guidelines based on real Anthropic code
- Code analysis tools that identify quality patterns
- Development utilities that support team coding standards
- Shared coding standards documentation for community

### Scenario 4: Quality Discovery through Testing Analysis
**SDLC Phase:** Testing & Quality Assurance  
**Discovery Focus:** How does Anthropic test their systems? What quality standards do they maintain?

**Skills Practice:**
- **API Integration:** Use Claude to analyze testing approaches and quality metrics
- **Prompt Engineering:** Create prompts that evaluate code quality and testing coverage
- **Evaluation:** Build comprehensive evaluation frameworks for prompt and system quality
- **Tool Integration:** Develop automated testing tools that align with Anthropic's quality standards

**Quality Gates:**
- Testing framework covers major quality dimensions (functionality, performance, security)
- Automated tools demonstrate improved testing efficiency
- Community feedback validates testing approach effectiveness

**Deliverables:**
- Quality assurance framework based on Anthropic's practices
- Automated testing tools and evaluation pipelines
- Quality metrics and monitoring systems
- Open-source testing utilities for community use

### Scenario 5: Deployment Discovery through DevOps Analysis
**SDLC Phase:** Deployment & CI/CD  
**Discovery Focus:** How does Anthropic deploy and maintain their systems? What DevOps practices do they use?

**Skills Practice:**
- **API Integration:** Use Claude to understand deployment patterns and infrastructure choices
- **Prompt Engineering:** Write prompts that identify DevOps best practices and automation opportunities
- **Evaluation:** Test deployment strategies and measure their effectiveness
- **Tool Integration:** Build CI/CD tools and deployment automation that follows Anthropic's patterns

**Quality Gates:**
- DevOps playbook covers complete deployment lifecycle
- Automation tools demonstrate measurable deployment improvements
- Community validates DevOps practices and tools

**Deliverables:**
- DevOps playbook based on Anthropic's deployment practices
- Automated deployment tools and pipelines
- Infrastructure monitoring and management utilities
- Shared DevOps knowledge and tools for community

### Scenario 6: Maintenance Discovery through Operations Analysis
**SDLC Phase:** Operations & Maintenance  
**Discovery Focus:** How does Anthropic monitor, maintain, and improve their systems over time?

**Skills Practice:**
- **API Integration:** Use Claude to analyze maintenance patterns and operational metrics
- **Prompt Engineering:** Create prompts for system monitoring, issue detection, and continuous improvement
- **Evaluation:** Continuously measure and improve system performance and prompt effectiveness
- **Tool Integration:** Build operational tools for monitoring, alerting, and system optimization

**Quality Gates:**
- Operations handbook covers comprehensive maintenance practices
- Monitoring systems provide actionable insights and alerts
- Continuous improvement framework demonstrates measurable enhancements

**Deliverables:**
- Operations handbook based on Anthropic's maintenance practices
- Monitoring and alerting systems
- Continuous improvement frameworks and tools
- Community-shared operational knowledge and utilities

## Success Criteria
1. **Personal Learning:** Develop practical SDLC skills through real-world discovery
2. **Team Contribution:** Create shareable discoveries, tools, and documentation
3. **Process Improvement:** Build better ways to onboard future team members
4. **Community Value:** Contribute insights and tools back to Anthropic's ecosystem
5. **Quality Validation:** All discoveries validated through community engagement
6. **Knowledge Sharing:** Learn in the open with documented, shareable outcomes

**Goal:** Master software development lifecycle and DevOps principles through hands-on discovery of Anthropic's actual practices and codebase, while contributing valuable knowledge and tools to the community.