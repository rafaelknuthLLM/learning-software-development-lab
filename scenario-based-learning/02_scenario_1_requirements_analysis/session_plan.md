# Next Session Plan: Requirements Analysis with Prompt Engineering

## Session Goal
Build working prompt engineering and evaluation system using your software development learning journey as the real-world requirements gathering scenario.

## What We'll Actually Build

### 1. Setup Working Environment
- Create `requirements_analysis_prompts.ipynb` notebook with API connection
- Import necessary libraries (anthropic, pandas, csv handling)
- Test API connectivity and basic functionality

### 2. Engineer and Test Prompts
- Write prompts that help gather your learning requirements
- Test each prompt immediately with live API calls
- See real Claude responses, measure quality in real-time
- Focus on extracting: career goals → learning objectives → daily needs

### 3. Build Evaluation System
- Create `requirements_evaluation.ipynb` for systematic testing
- Implement evaluation metrics for requirement quality
- Build automated testing pipeline
- Store results in CSV files for analysis

### 4. Iterate Based on Results
- Modify prompts based on actual performance data, not theory
- A/B test different prompt approaches
- Refine based on measurable improvements
- Document what works and what doesn't

## Specific Hands-On Approach

**Real requirements gathering:**
- Use prompts to extract what you actually need to learn about software development
- Apply your top-down methodology: README → Structure → Folders → Code
- Focus on your consultant → developer transition

**Live testing:**
- Execute each prompt version immediately
- Capture Claude responses for analysis
- Measure effectiveness with concrete metrics

**Data-driven improvement:**
- Build evaluation metrics that matter
- Collect performance results in structured data
- Iterate based on evidence, not assumptions

## Deliverables by End of Session

✅ **Working Jupyter notebook** that gathers your learning requirements effectively
✅ **Evaluation framework** that measures prompt quality with real data  
✅ **Test data** showing which prompt versions perform best
✅ **Refined prompts** ready for actual use in your learning journey

## Key Difference
We're not just learning about prompt engineering - we're building a working system that you can actually use to clarify and organize your software development learning needs.

## Success Metrics
- Prompts generate actionable, specific learning requirements
- Evaluation system provides clear quality scores
- Test results show measurable improvement between versions
- Final system helps accelerate your actual learning process

Ready to code and test, not just plan.