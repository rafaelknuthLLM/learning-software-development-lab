{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements Analysis with Prompt Engineering\n",
    "\n",
    "**Scenario 1:** Using your actual software development learning journey as the real-world scenario to learn prompt engineering and evaluation.\n",
    "\n",
    "**Goal:** Build working system for clarifying software development learning needs while applying SDLC Requirements Analysis phase.\n",
    "\n",
    "## Approach\n",
    "- Top-down methodology: Start with big picture learning goals ‚Üí drill down to specific daily needs\n",
    "- Test each prompt immediately with live API calls\n",
    "- Measure effectiveness with concrete metrics\n",
    "- Iterate based on performance data, not theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import anthropic\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Anthropic client\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.getenv('ANTHROPIC_API_KEY')\n",
    ")\n",
    "\n",
    "print(\"‚úÖ API connection ready\")\n",
    "print(f\"üïí Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test API Connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quick API test\n",
    "def test_api_connection():\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=50,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Say 'API test successful' if you can read this.\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        print(\"‚úÖ API Test Result:\", response.content[0].text)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå API Test Failed:\", str(e))\n",
    "        return False\n",
    "\n",
    "test_api_connection()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Context\n",
    "\n",
    "**Current Situation:** Data/AI consultant transitioning to software developer\n",
    "**Learning Methodology:** Top-down approach, build-first, learn by contributing to Anthropic community\n",
    "**Immediate Need:** Clear, actionable learning requirements for daily progress\n",
    "\n",
    "Let's engineer prompts that help extract specific learning requirements from this high-level goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Version 1: Basic Requirements Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prompt V1: Direct question approach\n",
    "prompt_v1 = \"\"\"\n",
    "You are helping someone transition from data/AI consulting to software development. \n",
    "\n",
    "Based on this learning approach:\n",
    "- Learn by building and contributing to Anthropic's community\n",
    "- Prioritize velocity over perfection - ship early, iterate fast\n",
    "- Learn just enough to make the next step forward\n",
    "- Always use top-down methodology: README ‚Üí Structure ‚Üí Folders ‚Üí Code\n",
    "- Document discoveries in the open\n",
    "\n",
    "What are the most important software development skills they should focus on learning first?\n",
    "\"\"\"\n",
    "\n",
    "def test_prompt(prompt, version_name):\n",
    "    \"\"\"Test a prompt and return structured results\"\"\"\n",
    "    try:\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-3-haiku-20240307\",\n",
    "            max_tokens=500,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'version': version_name,\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'prompt': prompt.strip(),\n",
    "            'response': response.content[0].text,\n",
    "            'token_count': response.usage.output_tokens if hasattr(response, 'usage') else 'N/A'\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüß™ Testing {version_name}\")\n",
    "        print(f\"üìù Response ({result['token_count']} tokens):\")\n",
    "        print(result['response'])\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {version_name} failed:\", str(e))\n",
    "        return None\n",
    "\n",
    "# Test Prompt V1\n",
    "result_v1 = test_prompt(prompt_v1, \"Prompt V1\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Version 2: Structured Requirements with Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prompt V2: More structured with specific context and output format\n",
    "prompt_v2 = \"\"\"\n",
    "You are a software development mentor helping someone make a career transition.\n",
    "\n",
    "CONTEXT:\n",
    "- Current role: Data/AI consultant (has analytical skills, understands business requirements)\n",
    "- Goal: Become a software developer who contributes to Anthropic's community\n",
    "- Learning style: Top-down methodology (README ‚Üí Structure ‚Üí Folders ‚Üí Code)\n",
    "- Approach: Build-first, ship early, iterate fast, document discoveries\n",
    "- Time constraint: Daily progress needed, learn just enough for next step\n",
    "\n",
    "TASK:\n",
    "Generate a prioritized learning roadmap with specific, actionable requirements for the first 30 days.\n",
    "\n",
    "FORMAT YOUR RESPONSE AS:\n",
    "## Week 1-2 Priorities\n",
    "[List 3-4 specific skills/topics with brief rationale]\n",
    "\n",
    "## Week 3-4 Priorities  \n",
    "[List 3-4 specific skills/topics building on previous weeks]\n",
    "\n",
    "## Daily Learning Pattern\n",
    "[Suggest a daily routine that fits the build-first approach]\n",
    "\n",
    "Focus on skills that directly enable contributing to Anthropic's developer community.\n",
    "\"\"\"\n",
    "\n",
    "# Test Prompt V2\n",
    "result_v2 = test_prompt(prompt_v2, \"Prompt V2\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Version 3: Scenario-Based with Evaluation Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prompt V3: Scenario-based with built-in evaluation\n",
    "prompt_v3 = \"\"\"\n",
    "You are analyzing learning requirements for this specific scenario:\n",
    "\n",
    "SCENARIO: A data/AI consultant wants to transition to software development by building tools that help Anthropic's developer community. They're currently working through Anthropic's courses (API Fundamentals, Prompt Engineering, Tool Use) using a systematic SDLC approach.\n",
    "\n",
    "CURRENT SESSION: They're in \"Requirements Analysis\" phase, learning prompt engineering by building a working requirements gathering system.\n",
    "\n",
    "LEARNING CONSTRAINTS:\n",
    "- Must show daily progress with shipped code\n",
    "- Top-down methodology: big picture first, then details\n",
    "- Build working tools, not just study theory\n",
    "- Document everything for community benefit\n",
    "\n",
    "YOUR TASK: Identify the 5 most critical learning requirements for THIS WEEK that will enable them to:\n",
    "1. Successfully complete the current requirements analysis scenario\n",
    "2. Build something valuable for Anthropic's community\n",
    "3. Make measurable daily progress\n",
    "\n",
    "For each requirement, provide:\n",
    "- WHAT: Specific skill/knowledge needed\n",
    "- WHY: How it enables the scenario goals\n",
    "- HOW: Concrete next action they can take today\n",
    "- MEASURE: How they'll know they've learned it\n",
    "\n",
    "Focus on requirements that directly serve their current hands-on prompt engineering work.\n",
    "\"\"\"\n",
    "\n",
    "# Test Prompt V3\n",
    "result_v3 = test_prompt(prompt_v3, \"Prompt V3\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Results for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Store all results for evaluation\n",
    "all_results = [result_v1, result_v2, result_v3]\n",
    "valid_results = [r for r in all_results if r is not None]\n",
    "\n",
    "# Save to CSV for analysis\n",
    "if valid_results:\n",
    "    df = pd.DataFrame(valid_results)\n",
    "    \n",
    "    # Save to data directory\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    csv_filename = f'data/prompt_test_results_{timestamp}.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Results saved to: {csv_filename}\")\n",
    "    print(f\"üìä Total tests run: {len(valid_results)}\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\nüìã Results Summary:\")\n",
    "    for result in valid_results:\n",
    "        print(f\"- {result['version']}: {len(result['response'])} chars, {result['token_count']} tokens\")\nelse:\n",
    "    print(\"‚ùå No valid results to save\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Evaluate Results**: Compare responses for specificity, actionability, and relevance\n",
    "2. **Build Evaluation Framework**: Create systematic scoring in `requirements_evaluation.ipynb`\n",
    "3. **Iterate Prompts**: Refine based on performance data\n",
    "4. **Deploy Best Version**: Use refined prompts for actual learning requirements gathering\n",
    "\n",
    "**Key Questions for Evaluation:**\n",
    "- Which prompt generated the most actionable requirements?\n",
    "- Which response best serves the immediate learning scenario?\n",
    "- Which format makes it easiest to create daily learning plans?\n",
    "- Which version would most help someone in the same transition?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}